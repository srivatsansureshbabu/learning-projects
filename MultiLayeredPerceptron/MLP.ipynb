{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "features = []\n",
        "\n",
        "# Dataset for XOR prediction\n",
        "features.append(np.array([0,0]))\n",
        "features.append(np.array([0,1]))\n",
        "features.append(np.array([1,0]))\n",
        "features.append(np.array([1,1]))\n",
        "\n",
        "# XOR outputs\n",
        "y = np.array([0,1,1,0])\n",
        "\n",
        "# randomly generate weights and biases\n",
        "rng = np.random.default_rng()\n",
        "weights1 = rng.uniform(-1, 1, size=2)\n",
        "weights2 = rng.uniform(-1, 1, size=2)\n",
        "weights_output = rng.uniform(-1,1, size=2)\n",
        "\n",
        "#biases\n",
        "bias1 = rng.uniform(-2, 2)\n",
        "bias2 = rng.uniform(-2,2)\n",
        "bias_output = rng.uniform(-2,2)\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 0.25\n",
        "epochs = 500\n",
        "for i in range(epochs):\n",
        "  predictions = []\n",
        "  for i,feature in enumerate(features):\n",
        "\n",
        "    ## One layer\n",
        "    hidden_input1 = feature.dot(weights1) + bias1\n",
        "    hidden_input2 = feature.dot(weights2) + bias2\n",
        "\n",
        "    hidden_output1 = 1/ (1 + np.exp(-hidden_input1))\n",
        "    hidden_output2 = 1/ (1 + np.exp(-hidden_input2))\n",
        "\n",
        "    hidden_outputs = np.array([hidden_output1,hidden_output2])\n",
        "\n",
        "    # output of layer\n",
        "    output_input = weights_output.dot(hidden_outputs) + bias_output\n",
        "\n",
        "    y_pred = 1/(1+np.exp(-output_input))\n",
        "    # cross entropy loss function\n",
        "    loss = -(y[i]*np.log(y_pred) + (1-y[i]) * np.log(1-y_pred) )\n",
        "\n",
        "    # gradiants\n",
        "    output_delta = y_pred-y[i]\n",
        "    weights_output_grad = output_delta * hidden_outputs\n",
        "    bias_output_grad = y_pred-y[i]\n",
        "\n",
        "    weights_output = weights_output - learning_rate*weights_output_grad\n",
        "    bias_output = bias_output - learning_rate*bias_output_grad\n",
        "\n",
        "    # hidden deltas\n",
        "    hidden_delta1 = output_delta*weights_output[0]*hidden_output1*(1-hidden_output1)\n",
        "    hidden_delta2 = output_delta*weights_output[1]*hidden_output2*(1-hidden_output2)\n",
        "\n",
        "    # hidden weight gradients\n",
        "    hidden_weight_grad1 = hidden_delta1*feature\n",
        "    hidden_bias_grad1 = hidden_delta1\n",
        "    hidden_weight_grad2 = hidden_delta2*feature\n",
        "    hidden_bias_grad2 = hidden_delta2\n",
        "\n",
        "    # updating weights and biases\n",
        "    weights1 = weights1 -learning_rate* hidden_weight_grad1\n",
        "    bias1 = bias1-learning_rate*hidden_bias_grad1\n",
        "    weights2 = weights2 - learning_rate*hidden_weight_grad2\n",
        "    bias2 = bias2 - learning_rate*hidden_bias_grad2\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8bUvkao4Nld",
        "outputId": "3677255b-ec0d-4856-d0a0-e2b947d83a9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.float64(0.08129696801518953), np.float64(0.9554775543135332), np.float64(0.9214982985623248), np.float64(0.0656504570107692)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "\n",
        "model_output = []\n",
        "for i, feature in enumerate(features):\n",
        "\n",
        "  hidden_input1 = feature.dot(weights1) + bias1\n",
        "  hidden_input2 = feature.dot(weights2) + bias2\n",
        "\n",
        "  hidden_output1 = 1/(1+np.exp(-hidden_input1))\n",
        "  hidden_output2 = 1/(1+np.exp(-hidden_input2))\n",
        "\n",
        "  hidden_outputs = np.array([hidden_output1,hidden_output2])\n",
        "\n",
        "  output_input = hidden_outputs.dot(weights_output) + bias_output\n",
        "\n",
        "  y_pred = 1/(1+np.exp(-output_input))\n",
        "\n",
        "  model_output.append(y_pred)\n",
        "\n",
        "print(model_output) # should be close to [0,1,1,0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E1wkg1QC9c2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e429ba72-2196-4e30-dd31-1d585ae8c3f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.float64(0.08076350507431519), np.float64(0.9566232534775345), np.float64(0.9235054048325512), np.float64(0.06404209306076598)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UM8EuGoHTJM"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}