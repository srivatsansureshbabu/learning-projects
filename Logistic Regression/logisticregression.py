# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colab.

"""

import numpy as np

# Each array resembles a random val, [Hours studied,hours slept, practice problems]
features = []
features.append(np.array([1,5,0]))
features.append(np.array([2,6,1]))
features.append(np.array([3,5,2]))
features.append(np.array([4,7,3]))
features.append(np.array([5,6,3]))
features.append(np.array([6,8,4]))
features.append(np.array([1,7,2]))
features.append(np.array([3,8,3]))
features.append(np.array([2,5,1]))
features.append(np.array([4,6,3]))
y = np.array([0,0,0,1,1,1,0,1,0,1])


rng = np.random.default_rng()  # modern, recommended way
weights = rng.uniform(-1, 1, size=3)  # gives 3 random numbers between -1 and 1
bias = rng.uniform(-1, 1)

# Hyperparameters
learning_rate = 0.01
epochs = 30

#Graphing purposes
loss_history = []

# Training loop
for epoch in range(epochs):
  for i, x in enumerate(features):
    # getting correct operations for updating weights and biases
    y_prime = features[i].dot(weights) + bias
    sigmoid = 1/(1 + np.exp(-y_prime))
    error = -y[i]*np.log(sigmoid) + (1-y[i]) * np.log(1-sigmoid)
    loss_history.append(error) # for visuialization purposes only
    grad_w = (sigmoid-y[i])*features[i]
    grad_b = (sigmoid-y[i])

    # updating weights and biases
    for j, feature in enumerate(x): # each individual feature (length 3)
      weights[j] = weights[j] - learning_rate*(sigmoid-y[i])*x[j]
      bias = bias - learning_rate*(sigmoid-y[i])

# Testing dataset

features = []
features.append(np.array([2,5,2]))
features.append(np.array([3,6,2]))
features.append(np.array([4,7,3]))
features.append(np.array([5,6,4]))
features.append(np.array([1,8,1]))
features.append(np.array([6,7,4]))
y = np.array([0,0,1,1,0,1])

predictions = []
# testing loop
for i,feature in enumerate(features):
  y_prime = feature.dot(weights) + bias
  sigmoid = 1/(1+ np.exp(-y_prime))
  if( sigmoid >= 0.5):
    predictions.append(1)
  else:
    predictions.append(0)


# checking the accuracy
count = 0
length = len(predictions)
for i, output in enumerate(y):
  if predictions[i] == y[i]:
    count = count + 1

print((count/length)*100,'%')

import matplotlib.pyplot as plt

# --- Inside your training loop, after computing 'error' ---
# Instead of modifying your original code, just append the error
# This goes right after `error = -y[i]*np.log(sigmoid) + (1-y[i]) * np.log(1-sigmoid)`
loss_history.append(error)

# --- After your training/testing loops ---
# Plot the loss over iterations
plt.plot(loss_history)
plt.xlabel('Training Step (iteration)')
plt.ylabel('Cross-Entropy Loss')
plt.title('Training Loss over Time')
plt.show()