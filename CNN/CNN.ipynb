{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/CIFAR 10/cifar-10-python.tar.gz'\n",
        "!tar -xvzf \"/content/drive/MyDrive/CIFAR 10/cifar-10-python.tar.gz\" -C /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8bUvkao4Nld",
        "outputId": "7ab92ee8-508f-4ab2-fbef-4396c96e2d37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Path to a batch file\n",
        "batch_file = '/content/cifar-10-batches-py/data_batch_1'\n",
        "\n",
        "# Load the batch\n",
        "with open(batch_file, 'rb') as f:\n",
        "    batch = pickle.load(f, encoding='bytes')\n",
        "\n",
        "# Extract data and labels\n",
        "data = batch[b'data']          # shape: (10000, 3072)\n",
        "labels = batch[b'labels']      # list of length 10000\n",
        "\n",
        "# Reshape data into images: (num_samples, 3, 32, 32)\n",
        "images = data.reshape(-1, 3, 32, 32)\n",
        "\n",
        "# Optional: convert to float and normalize 0â€“1\n",
        "images = images.astype('float32') / 255.0\n",
        "\n",
        "print(f\"Images shape: {images.shape}, Labels length: {len(labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA0sD1xNcEyY",
        "outputId": "ff69e93f-3272-44c6-df83-3f4073afb676"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: (10000, 3, 32, 32), Labels length: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for idx,image in enumerate(images):\n",
        "\n",
        "  # \"weights\" and bias\n",
        "  kernel = np.random.uniform(-0.1, 0.1, (3,3, 3)) # think of this as the weights for the kernel\n",
        "  bias = np.random.uniform(-1,1)\n",
        "\n",
        "  # dimensions for convoluting\n",
        "  channels = len(image)\n",
        "  height = len(image[0])\n",
        "  width = len(image[0][0])\n",
        "\n",
        "  # new convoluted array\n",
        "  outputs = np.zeros((3, 30, 30))\n",
        "  count = 0\n",
        "\n",
        "  # convoluting\n",
        "  for i in range(height-2):\n",
        "    for j in range(width-2):\n",
        "      patch = image[:,i:i+3,j:j+3] # (3,3)\n",
        "      outputs[0][i][j] = np.sum(kernel*patch) + bias\n",
        "      count = count+1\n",
        "  # RELU (make all negatives into 0 )\n",
        "  # outputs (3,30,30)\n",
        "  height = len(outputs[0])\n",
        "  width = len(outputs[0][0])\n",
        "\n",
        "  outputs = np.where(outputs > 0, outputs, 0)\n",
        "\n",
        "  # Max pooling\n",
        "  output_pool = np.zeros((15,15))\n",
        "  for i in range(0,height,2):\n",
        "    for j in range(0,width,2):\n",
        "      max_pool_section = outputs[0,i:i+2,j:j+2]\n",
        "      max_pool = np.max(max_pool_section)\n",
        "      output_pool[int(i/2)][int(j/2)] = max_pool\n",
        "  # Flatten\n",
        "\n",
        "  flattened_vector = output_pool.reshape(15*15)\n",
        "  weights = np.random.uniform(-.1,.1, (225,10))\n",
        "  bias = np.random.uniform(-.1,.1, (10,))\n",
        "\n",
        "  fully_connected_output = flattened_vector.dot(weights) + bias\n",
        "\n",
        "  prediction = np.argmax(fully_connected_output)\n",
        "\n",
        "  predictions.append(prediction)\n"
      ],
      "metadata": {
        "id": "XmMutQwVgyK9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.sum(predictions == labels) / len(labels)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4qkEqLxLPnr",
        "outputId": "f3896e1f-5099-418b-979b-0caf240c15bf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}